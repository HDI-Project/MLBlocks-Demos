{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from btb import HyperParameter, ParamTypes\n",
    "from btb.tuning import GP\n",
    "from mlblocks.mlpipeline import MLPipeline\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuner(pipeline):\n",
    "    tunables = [\n",
    "        ((p.block_name, p.param_name), HyperParameter(p.param_type, p.param_range))\n",
    "        for p in pipeline.get_tunable_hyperparams()\n",
    "    ]\n",
    "    return GP(tunables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(obs, exp):\n",
    "    return f1_score(obs, exp, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(X, y, blocks, params, score_func, splits=5):\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "    scores = list()\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        pipeline = MLPipeline(blocks)\n",
    "        pipeline.set_from_hyperparam_dict(params)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        scores.append(score_func(y_pred, y_test))\n",
    "    \n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(X, y, blocks, score_func, budget=20, splits=5):\n",
    "    pipeline = MLPipeline(blocks)\n",
    "    tuner = get_tuner(pipeline)\n",
    "    for _ in range(budget):\n",
    "        params = tuner.propose()\n",
    "        score, std = cv_score(X, y, blocks, params, score_func, splits)\n",
    "        tuner.add(params, score)\n",
    "        \n",
    "        yield params, score, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xals/envs/MLBlocks-Demos/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "blocks = ['random_forest_classifier']\n",
    "\n",
    "steps = list(make_pipeline(X, y, blocks, scorer, splits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9439417568829332, 0.017855183211689985),\n",
       " (0.9437830267242031, 0.03131900835750861),\n",
       " (0.9552115981527747, 0.013268148148532872),\n",
       " (0.9439417568829332, 0.025048942948389222),\n",
       " (0.9439417568829332, 0.025048942948389222),\n",
       " (0.9772922502334268, 0.011369949981975243),\n",
       " (0.9498061927473692, 0.01982641164521094),\n",
       " (0.9828478057889823, 0.014014239478014388),\n",
       " (0.9830065359477125, 0.013887927686846917),\n",
       " (0.9828478057889823, 0.014014239478014388),\n",
       " (0.9606170035581801, 0.01388337756569935),\n",
       " (0.9661725591137357, 0.011683743470801295),\n",
       " (0.9771335200746967, 0.021389639749015147),\n",
       " (0.9828478057889823, 0.014014239478014388),\n",
       " (0.988562091503268, 0.014018046136945897),\n",
       " (0.9664814394226159, 0.01028551947204806),\n",
       " (0.9715779645191411, 0.01808041701803548),\n",
       " (0.9828478057889823, 0.014014239478014388),\n",
       " (0.9496560425972191, 0.020472801142455862),\n",
       " (0.9771335200746967, 0.021389639749015147)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(score, std) for (_, score, std) in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('rf_classifier', 'criterion'): 'entropy',\n",
       " ('rf_classifier', 'max_features'): 0.1684225701771657,\n",
       " ('rf_classifier', 'max_depth'): 6,\n",
       " ('rf_classifier', 'min_samples_split'): 2,\n",
       " ('rf_classifier', 'min_samples_leaf'): 3,\n",
       " ('rf_classifier', 'n_estimators'): 100,\n",
       " ('rf_classifier', 'n_jobs'): -1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps[-1][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
